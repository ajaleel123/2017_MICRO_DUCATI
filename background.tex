% !TEX root = main.tex
% \newpage

\section{Background and Motivation} 
\label{sec:background}

\noindent Virtual memory is ubiquitous in nearly all computing systems
today and is responsible for translating virtual addresses to physical
addresses. Address translation is performed by maintaining an
application {\em page table} in system memory.
Figure~\ref{fig:page_table} shows a typical four-level hierarchical
page table commonly used in computing systems today. Each node in the
page table is 4KB in size and contains 512 8-byte entries that point
to the next node in the page table. The leaf node contains the
physical address mapping. Generally, the page table is sparsely
populated and new nodes are created only when data is referenced. As
such, the typical in-memory storage space for the application page
table is roughly 0.2\% of the total memory footprint (8 bytes of
storage overhead when using 4KB pages).

% Modern processors provide hardware support for address translation
% using the Memory Management Unit (MMU) and Input/Output MMU (IOMMU).
% The MMU handles CPU requests while the IOMMU handles device requests
% (e.g. GPU). 

Figure~\ref{fig:page_table} illustrates a {\em page walk} for a
four-level page table. The Memory Management Unit (MMU) (or page
walker) first consults a predetermined register (e.g. CR3 register on
x86 systems) to determine the physical address for Page Map Level 4
(PML4) or root node of the page table. The MMU indexes PML4 to fetch
the Page Directory Pointer (PDP) or third-level page table (first
memory reference). Next, the MMU indexes the PDP to fetch the Page
Directory (PD) or second-level page table (second memory reference).
Next, the MMU indexes the PD to fetch the first-level of the Page
Table (PT) (third memory reference). Finally, the MMU indexes the PT
(fourth memory reference) to fetch the physical address mapped to the
virtual address.

% \footnote{\noindent \small{In a virtualized environment, a
% page walk by the guest operating system may require up to 16 memory
% references}}.

% \begin{figure}[t] 
% \vspace{0. in}
% \centering
% \centerline{\psfig{file=GRAPHS/motivation_perf_mpki,angle=-90,width=\columnwidth}}
% 
% 	\caption{\small Workloads incur significant performance
% 	overhead due to frequent LLT misses. \normalsize}
% 
% \label{fig:llt_missrate} 
% \vspace{-0.15 in}
% \end{figure}

%\begin{figure}[t] 
%\vspace{0. in}
%\centering
%\centerline{\psfig{file=GRAPHS/tlb_sensitivity,angle=-90,width=\columnwidth}}

%	\caption{\small Performance Sensitivity to LLT Entries. \normalsize}

%\label{fig:tlb_sensitivity} 
%\vspace{-0.15 in}
%\end{figure}
\begin{figure}[t]
\vspace{0. in}
\centering
\centerline{\psfig{file=FIGURES/config,scale=0.4,angle=-90}}

        \caption{\small Baseline System. \normalsize}

\label{fig:config}
\vspace{-.2 in}
\end{figure}


To reduce page table accesses on an LLT miss, commercial processors
employ Page Walk Caches (PWC) for each page table level~\cite{SkipPT,
MMUcaches}. PWCs exploit temporal and spatial locality in the page
table access stream and avoid memory accesses on PWC hits.
Consequently, the frequency of TLB misses and PWC hit rates impacts
address translation performance.

\input{workloads}

In the previous section, Figure~\ref{fig:tlb_sensitivity} motivated
increasing TLB coverage by demonstrating its direct impact on
performance. To provide further insight, Table~\ref{table:bench_char}
shows the number of LLT misses for the evaluated workloads. We observe
that these workloads incur frequent LLT misses when using 4KB pages.
To make things worse, each LLT miss requires more than one memory
access to the page table (maximum of two in some cases). Consequently,
these workloads experience significant performance overheads due to
TLB misses. With the number of levels in the page table hierarchy
expected to grow to 5-levels~\cite{x86_5level}, there is a need for
reducing the number of memory accesses on an LLT miss in addition to
improving LLT coverage. Before we describe our solutions to address
both these problems, we first provide details on our experimental
methodology.


