%!TEX root=main.tex

\begin{abstract}

\it{\noindent Conventional on-chip TLB hierarchies are unable to fully
cover growing application memory footprints. To make things worse,
Last-Level TLB (LLT) misses require multiple accesses to the page
table (despite the use of page walk caches). Consequently, LLT misses incur long address translation latency. This paper focuses on reducing the frequency and penalty of on-die LLT misses. We propose {\em Unified CAche and TLB (UCAT)}, a hardware mechanism that enables the conventional on-die Last-Level Cache (LLC) to store cache lines and TLB entries in a single unified structure. Our evaluation using GPU workloads shows that UCAT increases on-die TLB coverage by R\% and improves GPU performance by X\% on average (up to Y\%). When UCAT is unable to fully cover total application memory footprint, we also propose {\em DRAM-TLB}, a hardware mechanism to memoize virtual to physical address translations in DRAM. DRAM-TLB serves as the next larger level in the TLB hierarchy that significantly increases TLB coverage relative to on-chip TLBs. We show that DRAM-TLBs architected using emerging stacked memory technology improves GPU performance by X\% on average (up to Y\%). Finally, we propose {\em DUCATI}, an address translation architecture that combines DRAM-TLBs and UCAT to reduce LLT miss penalty and improve on-die TLB coverage respectively. DUCATI improves performance by Z\% while requiring minimal changes to the existing virtual memory system design.}

\end{abstract}



% Consequently, frequent misses in the Last-Level TLB (LLT) rely on the
% Memory Management Unit (MMU) for high performance virtual address
% translation.
% 


% LocalWords:  gigascale ARchitecture
