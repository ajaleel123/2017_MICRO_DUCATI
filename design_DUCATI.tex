\section{DUCATI: Combining DRAM-TLBs \newline and UCAT}
\label{sec:DUCATI}

\noindent UCAT and DRAM-TLB both independently improve on-die
processor TLB coverage and LLT miss overhead respectively. Both these
mechanisms can be combined to collectively improve processor
performance. To that end, we propose {\em DUCATI}, an address
translation architecture that combines \underline{D}RAM-TLBs and
\underline{UCAT-I}. While DUCATI can be architected with Stacked-TLBs
or SYSMEM-TLBs, we limit our analysis of DUCATI with Stacked-TLBs
since DRAM-TLB architected with system memory technology is higher
performing than with conventional DDR memory technology.

\subsection{DUCATI Performance}

\begin{figure}[tp] 
\vspace{-0 in} \centering
\centerline{\psfig{file=GRAPHS/SUMMARY_perf,angle=-90,width=\columnwidth}}

\caption{\small Performance Summary (4KB page size).\normalsize}
\label{fig:summary_4k_pages_perf} 
\vspace{0.1 in}
\end{figure}

\begin{figure}[tp] 
\vspace{0.1 in} \centering
\centerline{\psfig{file=GRAPHS/SUMMARY_tlblat,angle=-90,width=\columnwidth}}

\caption{\small Translation Latency (4KB page size) (same legend as
  Figure~\ref{fig:summary_4k_pages_perf}).\normalsize}
\label{fig:summary_4k_pages_lat} 
\vspace{-0. in}
\end{figure}

\noindent Figure~\ref{fig:summary_4k_pages_perf} illustrates the
relative performance of our proposals to the baseline system. The
x-axis shows the different workloads while the y-axis illustrates
performance. For each workload, we present the relative performance
for DRAM-TLBs architected with stacked memory (i.e. Stacked-TLB),
Unified Cache and TLB (UCAT) enhanced with insertion (UCAT-I), DUCATI,
and for comparison the unbuildable Perfect Last-Level TLB (LLT)
system. To correlate the reasons for performance improvement,
Figure~\ref{fig:summary_4k_pages_lat} presents the relative address
translation for the different proposals.

Figure~\ref{fig:summary_4k_pages_perf} shows that DRAM-TLBs
architected with stacked memory improves average performance by 22\%,
UCAT with insertion (UCAT-I) improves average performance by 61\%,
while DUCATI combines the benefits of both to improve average
performance by 81\%. In fact, workloads like $XSBench$, $dmr$,
$MaxFlow$, and $MCB$ experience 4x or more performance improvement.
The bulk of the gain for these workloads is improvements in on-die LLT
coverage. On the other hand, $GUPS$ has a 2.5x performance primarily
due to reduction in LLT miss penalty (i.e., DRAM-TLB component of
DUCATI). All other workloads experience performance gains between 6\%
to 35\%.

To correlate performance improvements,
Figure~\ref{fig:summary_4k_pages_lat} illustrates the relative address
translation latency for the different proposals. On average, DRAM-TLB
and UCAT reduce address translation latency by 40\% and 60\%
respectively, while DUCATI reduces address translation latency by
75\%. In doing so, DUCATI improves performance by 1.81x while a
perfect LLT system improves performance by 2.24x. Thus, DUCATI bridges
80\% of the performance gap between the baseline system and an
unrealistic perfect LLT system.

% Note that Figure~\ref{fig:summary_4k_pages_lat} clearly identifies
% workloads that are are LLT capacity bound versus those workloads that
% are LLT miss penalty bound. Specifically, workloads where the first
% bar (DRAM-TLB) is lower than the second bar (UCAT) are those that
% limited by LLT miss penalty


\subsection{DUCATI Sensitivity to Page Size}

\noindent We now present the performance of our proposals using 64KB
and 2MB page size. For our 1024-entry baseline LLT size, using 4KB
pages provides TLB coverage of 4MB, using 64KB pages increases the TLB
coverage to 64MB, while using 2MB pages increases the TLB coverage to
2GB. Figure~\ref{fig:summary_4k_pages_perf} illustrates the average
performance across all workloads for 4KB, 64KB, and 2MB pages.
Overall, DUCATI improves performance by 81\% with 4KB pages, 56\% with
64K pages, and 8\% with 2MB pages. In fact, DUCATI is within 80\%,
95\%, and 98\% of an unrealstic perfect LLT system when using 4KB,
64KB, and 2MB pages respectively.

\begin{figure}[tp] 
\vspace{0. in} \centering
\centerline{\psfig{file=GRAPHS/pagesize_sensitivity2,angle=-90,width=\columnwidth}}

\caption{\small Performance Sensitivity to Page Size (same legend as
Figure~\ref{fig:summary_4k_pages_perf}). \normalsize}

\label{fig:summary_pagesize} 
\vspace{-0. in}
\end{figure}

% \subsection{Sensitivity to Stacked DRAM Bandwidth}
% 
% \noindent Figure~\ref{fig:stack_bw_sense} illustrates the sensitivity
% of our proposals to stacked memory bandwidth. We evaluate four
% additional systems with 0.25X, 0.5X, 2X, and 4X the stacked memory
% bandwidth of the baseline system (we do not vary the system memory
% bandwidth). We increased the bandwidth by increasing the number of
% channels in the stacked memory system. The y-axis illustrates the
% average performance relative to the baseline system across all
% workloads in the study.
% 
% The figure shows that when the stacked memory bandwidth is plentiful,
% our proposals continue to improve performance. However, when the
% stacked memory bandwidth becomes a bottleneck, the memory queuing
% delays limit the performance of Distributed Placement. Under such
% scenarios, Stacked-TLBs still improve performance since they reduce
% the number of memory references. In general, our proposals efficiently
% utilize the spare bandwidth available in the stacked memory system.
% When the available bandwidth is high, performance improvements are
% high. When the available bandwidth is low, performance improvements
